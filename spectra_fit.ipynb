{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import *\n",
    "from morfeus_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 matching comp and exp spectra\n",
      "on average each complex has 2.0 conformers\n"
     ]
    }
   ],
   "source": [
    "# initialize the conformer tracker\n",
    "monomers = np.arange(50)+1\n",
    "combs = []\n",
    "for comb in itertools.combinations(monomers, 2):\n",
    "    combs.append(list(comb))\n",
    "conf_tracker = dict((\"_\".join(map(str, el)), {\"exp_file\": \"\", \"comp_file\": []}) for el in combs)\n",
    "\n",
    "# identify matches with experimental data\n",
    "matches, conf_tracker = identify_matches(conf_tracker=conf_tracker)\n",
    "avg_confs = np.mean(np.array([len(conf_tracker[key]) for key in list(conf_tracker.keys())]))\n",
    "print(f\"on average each complex has {round(avg_confs, 3)} conformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training examples: 876\n",
      "  testing examples: 292\n",
      "  feature size: 640\n",
      "  target size: 311\n",
      "\n",
      "  **Using GPU**\n",
      "\n",
      "----- Initializing and returning model and likelihood -----\n",
      "\n",
      "\n",
      "  **Using GPU**\n",
      "\n",
      "----- Running Predictions -----\n",
      "\n",
      "\tlabeling 1/876, train: True\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 276.50 GiB (GPU 0; 23.68 GiB total capacity; 30.79 MiB already allocated; 22.49 GiB free; 44.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m# Run prediction and replace COMP spectra with prediction from MODEL\u001b[39;00m\n\u001b[1;32m     37\u001b[0m comp_model \n\u001b[0;32m---> 38\u001b[0m mean_train_preds, training \u001b[39m=\u001b[39m predict(comp_model, comp_likelihood, training, target\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomp_y\u001b[39;49m\u001b[39m\"\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, interval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, GPU\u001b[39m=\u001b[39;49mGPU, load\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomp_model.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     39\u001b[0m mean_test_preds, testing \u001b[39m=\u001b[39m predict(comp_model, comp_likelihood, testing, target\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomp_y\u001b[39m\u001b[39m\"\u001b[39m, interval\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, GPU\u001b[39m=\u001b[39mGPU, load\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomp_model.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m training[\u001b[39m\"\u001b[39m\u001b[39mcomp_y\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mean_train_preds\n",
      "File \u001b[0;32m~/OG/model_utils.py:418\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, likelihood, testing_df, training_data, target, train, compare, plot, interval, GPU, load)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), gpytorch\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mfast_pred_var():\n\u001b[1;32m    417\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m--> 418\u001b[0m     pred \u001b[39m=\u001b[39m likelihood(model(x)) \u001b[39m# get hyperparameter predictions\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[39m# Get the variance? How could we use this?\u001b[39;00m\n\u001b[1;32m    420\u001b[0m mean_pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mtolist() \u001b[39m# get mean predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:320\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m# Make the prediction\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mwith\u001b[39;00m settings\u001b[39m.\u001b[39mcg_tolerance(settings\u001b[39m.\u001b[39meval_cg_tolerance\u001b[39m.\u001b[39mvalue()):\n\u001b[0;32m--> 320\u001b[0m     predictive_mean, predictive_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_strategy\u001b[39m.\u001b[39;49mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    322\u001b[0m \u001b[39m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    323\u001b[0m predictive_mean \u001b[39m=\u001b[39m predictive_mean\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mbatch_shape, \u001b[39m*\u001b[39mtest_shape)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:273\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    268\u001b[0m     test_test_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :]\n\u001b[1;32m    269\u001b[0m     test_train_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train]\n\u001b[1;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[0;32m--> 273\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[1;32m    274\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:335\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_covar\u001b[0;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[39m# In other cases - we'll use the standard infrastructure\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         \u001b[39mreturn\u001b[39;00m test_test_covar \u001b[39m+\u001b[39m MatmulLinearOperator(test_train_covar, covar_correction_rhs\u001b[39m.\u001b[39mmul(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 335\u001b[0m precomputed_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovar_cache\n\u001b[1;32m    336\u001b[0m covar_inv_quad_form_root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exact_predictive_covar_inv_quad_form_root(precomputed_cache, test_train_covar)\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(test_test_covar):\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/gpytorch/models/exact_prediction_strategies.py:229\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.covar_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    226\u001b[0m \u001b[39m@cached\u001b[39m(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcovar_cache\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcovar_cache\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    228\u001b[0m     train_train_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlik_train_train_covar\n\u001b[0;32m--> 229\u001b[0m     train_train_covar_inv_root \u001b[39m=\u001b[39m to_dense(train_train_covar\u001b[39m.\u001b[39;49mroot_inv_decomposition()\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_test_train_covar)\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:2812\u001b[0m, in \u001b[0;36mto_dense\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2810\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m   2811\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, LinearOperator):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mto_dense()\n\u001b[1;32m   2813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2814\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mobject of class \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m cannot be made into a Tensor\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/linear_operator/operators/matmul_linear_operator.py:120\u001b[0m, in \u001b[0;36mMatmulLinearOperator.to_dense\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39m@cached\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_dense\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmatmul(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_linear_op\u001b[39m.\u001b[39;49mto_dense(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_linear_op\u001b[39m.\u001b[39mto_dense())\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/.conda/envs/gpytorch/lib/python3.10/site-packages/linear_operator/operators/diag_linear_operator.py:110\u001b[0m, in \u001b[0;36mDiagLinearOperator.to_dense\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_diag\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_diag\n\u001b[0;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mdiag_embed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_diag)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 276.50 GiB (GPU 0; 23.68 GiB total capacity; 30.79 MiB already allocated; 22.49 GiB free; 44.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "##### PREDICTING DIMER COMPUTATIONAL SPECTRUM FROM MONOMER SPECTRA AND FINGERPRINTS #####\n",
    "\n",
    "# First load all complexes\n",
    "master = pd.read_pickle(\"complexes_1168_boltz_weighted.pkl\")\n",
    "samples = master\n",
    "\n",
    "# Load monomer data\n",
    "data = load_monomer(\"comp_spectral_data/excited_state_monomer_spectra_csvs/\", n_pts=64)\n",
    "\n",
    "# Split into train and test sets \n",
    "training, testing = split_data(samples, test_size=0.25)\n",
    "\n",
    "# Generate features from monomer spectra and fingerprints for both train and testing sets\n",
    "training = gen_features(training, \"comp_spectral_data/excited_state_monomer_spectra_csvs/\", \n",
    "                        data, monomer_features=True, add_fps=True, fp_bits=256)\n",
    "testing = gen_features(testing, \"comp_spectral_data/excited_state_monomer_spectra_csvs/\",\n",
    "                       data, monomer_features=True, add_fps=True, fp_bits=256)\n",
    "\n",
    "feature_size = len(training[\"training_features\"].tolist()[0])\n",
    "training, testing = shrink_spectrum(training, cut=1), shrink_spectrum(testing, cut=1)\n",
    "target_size = len(training[\"comp_y\"].tolist()[0])\n",
    "\n",
    "print(f\"  training examples: {training.shape[0]}\\n  testing examples: {testing.shape[0]}\\n  feature size: {feature_size}\\n  target size: {target_size}\")\n",
    "\n",
    "# train a multitask GP to predict COMPUTATIONAL DIMER SPECTRUM from features\n",
    "GPU = torch.cuda.is_available()\n",
    "if not os.path.exists(\"comp_model.pth\"):\n",
    "    train = True\n",
    "else:\n",
    "    train = False\n",
    "comp_model, comp_likelihood = train_multitask_GP(training, target=\"comp_y\", n_iterations=300, GPU=GPU, train=train)\n",
    "os.system(\"rm -rf after_training/\")\n",
    "if train:\n",
    "    torch.save(comp_model.state_dict(), \"comp_model.pth\")\n",
    "\n",
    "# Run prediction and replace COMP spectra with prediction from MODEL\n",
    "comp_model \n",
    "mean_train_preds, training = predict(comp_model, comp_likelihood, training, target=\"comp_y\", train=True, interval=100, GPU=GPU, load=\"comp_model.pth\")\n",
    "mean_test_preds, testing = predict(comp_model, comp_likelihood, testing, target=\"comp_y\", interval=50, GPU=GPU, load=\"comp_model.pth\")\n",
    "\n",
    "training[\"comp_y\"] = mean_train_preds\n",
    "testing[\"comp_y\"] = mean_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   30403 KB |   74127 KB |  432333 KB |  401929 KB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   30403 KB |   74127 KB |  432333 KB |  401929 KB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   45056 KB |   88064 KB |   88064 KB |   43008 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   14652 KB |   35965 KB |  466803 KB |  452151 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     679    |     697    |     998    |     319    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     679    |     697    |     998    |     319    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       4    |       8    |       8    |       4    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      10    |      12    |     156    |     146    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=0, abbreviated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoin training and testing DataFrames \n",
    "exp_samples = pd.concat([training, testing]).dropna()\n",
    "\n",
    "# Split into train and test sets \n",
    "training, testing = split_data(exp_samples, test_size=0.25)\n",
    "\n",
    "# Generate features from dimer spectra, monomer spectra, and fingerprints for both train and testing sets\n",
    "training = gen_features(training, \"comp_spectral_data/excited_state_monomer_spectra_csvs/\", \n",
    "                        data, monomer_features=True, add_fps=True, fp_bits=128, comp_features=True)\n",
    "testing = gen_features(testing, \"comp_spectral_data/excited_state_monomer_spectra_csvs/\",\n",
    "                       data, monomer_features=True, add_fps=True, fp_bits=128, comp_features=True)\n",
    "                       \n",
    "feature_size = len(training[\"training_features\"].tolist()[0])\n",
    "target_size = len(training[\"exp_y\"].tolist()[0])\n",
    "\n",
    "print(f\"training examples: {training.shape[0]}\\ntesting examples: {testing.shape[0]}\\nfeature size: {feature_size}\\ntarget size: {target_size}\")\n",
    "\n",
    "##### predicting EXPERIMENTAL DIMER SPECTRUM from PREDICTED COMP SPECTRA, MONOMER SPECTRA, and FPs #####\n",
    "GPU = torch.cuda.is_available()\n",
    "if not os.path.exists(\"exp_model.pth\"):\n",
    "    train = True\n",
    "else:\n",
    "    train = False\n",
    "exp_model, exp_likelihood = train_multitask_GP(training, target=\"exp_y\", n_iterations=250, GPU=GPU, train=True)\n",
    "if train:\n",
    "     torch.save(comp_model.state_dict(), \"exp_model.pth\")\n",
    "\n",
    "# Run predictions\n",
    "mean_train_preds, training = predict(exp_model, exp_likelihood, training, target=\"exp_y\", train=True, plot=True, compare=True, load=\"exp_model.pth\")\n",
    "mean_test_preds, testing = predict(exp_model, exp_likelihood, testing, target=\"exp_y\", plot=True, compare=True, load=\"exp_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_after = pd.concat([testing[\"R2_after\"], training[\"R2_after\"]])\n",
    "mae_after = pd.concat([testing[\"MAE_after\"], training[\"MAE_after\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e93e96c4ddd49033ef8e33d3308122769f03223b8ba9a0f77b90609941865f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
